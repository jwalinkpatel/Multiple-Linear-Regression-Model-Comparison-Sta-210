---
title: "HW 04: Multiple linear regression"
author: "Jwalin Patel"
date: "03/24/2021"
output: 
  pdf_document: 
    fig_height: 4
    fig_width: 6
---

```{r load-packages, warning = FALSE, message = FALSE}
library(tidyverse)
library(broom)
library(knitr)
library(patchwork)
```

```{r load-data, warning = FALSE, message = FALSE}
sitting <- read.csv("data/sitting.csv")
```

## Part 1 

### Question 1
We will use SLR to model MET and sitting as predictor and response variables, respectively. 
$$Simple\ Linear\ Regression\ Model: sitting = \beta_0 + \beta_1{MET}$$
```{r}
m1 <- lm(sitting ~ MET, data = sitting)
m1 %>%
  tidy(conf.int = TRUE) %>%
  kable (digits = 3, caption = "Prediction of the Reported hours per day spent sitting for subjects given reported metabolic equivalent unit minutes per week")
```
Now we calculate $R^2$ to consider how well the model fits the relationship between reported hours per day spent sitting and the reported metabolic equivalent unit minutes per week. 
```{r}
anova(m1) %>%
  kable(digits = 3)
```
We calculate $R^2$ using the formula:
$$R^{2} = \displaystyle \frac{SS_{Model}}{SS_{Total}}$$ 
```{r}
2.008/(2.008+373.592)
```
Thus, $R^2 = 0.005346113$. This means only around 0.53 percent of the variation in the reported hours per day spent sitting is explained by the reported metabolic equivalent unit minutes per week. Since the model only considers one predictor variable to explain variation in sitting hours, this is not a good representation of sitting hours.

### Question 2
```{r}
m2 <- lm(MTL ~ sitting, data = sitting)
m2 %>%
  tidy(conf.int = TRUE) %>%
  kable (digits = 3, caption = "Prediction of the Medial temporal lobe thickness in mm for subjects given Reported hours per day spent sitting")
```
The coefficient is estimated as -0.023, with expected value ranging from lower bound of -0.042 and upper bound of -0.004. This means we are 95% confident that with every 1 hour increase in Reported hours per day spent sitting for subjects, we can expect the Medial temporal lobe thickness to reduce by 0.004 to 0.042 mm, and reduce by 0.023 mm on average. 

### Question 3
```{r}
sitting %>%
  summarize (mean = mean(age))
sitting <- sitting %>% 
  mutate(age_cent = age - 60.37143)
m3 <- lm(MTL ~ sitting + MET + age_cent, data = sitting)
m3 %>%
  tidy(conf.int = TRUE) %>%
  kable (digits = 3, caption = "Prediction of the Medial temporal lobe thickness in mm for subjects given Reported hours per day spent sitting, Reported metabolic equivalent unit minutes per week and Mean centered age")
```
Sitting: The coefficient of sitting is estimated as  -0.021, with expected value ranging from lower bound of -0.040 and upper bound of -0.001. This means we are 95% confident that with every 1 hour increase in Reported hours per day spent sitting for subjects, we can expect the Medial temporal lobe thickness to reduce by 0.001 to 0.040 mm, and reduce by 0.021 mm on average, ceteris paribus. 
Age: 

### Question 4
```{r}
glance(m2) %>% 
  select(r.squared, adj.r.squared, AIC, BIC)
glance(m3) %>% 
  select(r.squared, adj.r.squared, AIC, BIC)
```
1. Based on adjusted $R^2$ we would choose the first model. Even though the second model has higher $R^2$, it has a lower adjusted $R^2$ implying that there the tradeoff/penalty of adding MET and age_cent to our model is greater than their contribution to explanatory power. 
2. Based on AIC, we choose the model with the smaller value of AIC which indicates better fit, which is the first model. This means adding MET and age_cent to our model did not reduce the sum of squares error enough to give us a lower AIC. 
3. Based on BIC, we choose the model with the smaller value of BIC which indicates better fit, which is again, the first model. This means adding MET and age_cent to our model did not reduce the sum of squares error enough to give us a lower BIC. Note, BIC value is much higher in the second model also because BIC has a greater penalty for the addition of predictor variables to the regression model. 

### Question 5
```{r}
houses <- read.csv("data/KingCountyHouses.csv")
houses <- houses %>% 
  mutate(waterfront_boolean = as.logical(waterfront))
ggplot(data = houses, aes(y = price, x = sqft, color=waterfront_boolean,)) +
geom_point() +
labs(x = "Area (Square footage)",
y = "Price (USD)", title = "Price of houses with and without waterfront view in King County given Area in square footage")
```
From the visualization, while there is a general positive correlation between price and area of house, we can also see that houses without waterfront (waterfront = false; red color) seem to gain price slower with increasing area, as compared to houses with waterfront (waterfront = true; blue color). Therefore the lines of fit would not appear to be parallel, indicating the presence of an interaction effect happening, such that price in response to the square footage changes differently due to another variable, in this case: whether the house has waterfront view or not.   

## Part 2
...